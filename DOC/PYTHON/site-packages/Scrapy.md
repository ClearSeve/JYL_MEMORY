Scrapy
======

安装
----

Twisted需要vc编译工具，可以使用Twisted的whl进行安装。

pip install scrapy

pip install pypiwin32

创建项目
--------

scrapy startproject 项目名

(Scripts加入path环境变量)

建立爬虫
--------

spiders目录下建立文件

jyl_spider.py

import scrapy

class BlogSpider(scrapy.Spider):

name = 'jyl' \#爬虫类的name属性，用来标识爬虫，该名字在一个项目必须是唯一的。

\#allowed_domains = [] \#限制只爬取这个域名下的网页

start_urls = ['https://blog.scrapinghub.com']

def parse(self, response):

for title in response.css('h2.entry-title'):

yield {'title': title.css('a ::text').extract_first()}

运行
----

项目目录（scrapy.cfg同级）下运行

scrapy crawl jyl

文件目录下运行

scrapy runspider jyl_spider.py -o ret.json

将（yield ）输出ret.json文件[可以是csv/XML]

调试
----

项目中建立新文件作为启动运行文件，文件内容：

from scrapy.cmdline import execute

\#import os

\#import sys

\#添加当前项目的绝对地址
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

\#执行 scrapy 内置的函数方法execute，使用 crawl 爬取并调试，最后一个参数是爬虫名

execute(['scrapy', 'crawl', 'jyl'])

设置
----

settings.py设置

ROBOTSTXT_OBEY = False

DEFAULT_REQUEST_HEADERS = {

'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML,
like Gecko) Chrome/50.0.2661.102 Safari/537.36',

'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,\*/\*;q=0.8',

'Accept-Language': 'en',

}

pipelines
---------

======创建piplelines

class JylPipeline(object):

def process_item(self, item, spider):

name = item['name']

return item \#继续传递item，下一个Pipeline可以接收

\#raise DropItem("drop %s" % item) \#扔掉item，下一个Pipeline不再接收

======settings.py设置加入piplelines

ITEM_PIPELINES = {

'jyl.pipelines.JylPipeline': 0,

}

0表示优先级数字，数字越小优先级越高

======调用方式1：

item定义：

class JylItem(scrapy.Item):

name = scrapy.Field()

from jyl.items import JylItem

ii = JylItem()

ii['name'] = imgSrc

yield ii

======调用方式2：

yield {"name": imgSrc}

创建请求
--------

爬虫类中，创建新请求，并使用当前类的回调函数

yield scrapy.Request(new_url,callback=self.parse)

response
--------

| 属性                     | 说明                                                                                  |
|--------------------------|---------------------------------------------------------------------------------------|
| url (string)             | response的 URL                                                                        |
| status (integer)         |                                                                                       |
| headers (dict)           | response头                                                                            |
| body (bytes)             | 如果是字符串可以用response.text                                                       |
| flags (list)             |                                                                                       |
| request (Request object) | Response.request初始属性                                                              |
| xpath                    | for imgSrc in response.xpath('//img/\@src').extract() 遍历所有img标签的src属性        |
|                          | .extract() 获取xpath对象内的所有数据，返回列表对象 .extract_first()返回列表第一个数据 |

shell
-----

scrapy shell "http://www.budejie.com/text/"

打开http://www.budejie.com/text/并进入shell命令

view(response)，打开默认浏览器并进入相应页面

response.css('title')，查看title的css样式

response.css('title::text').extract_first()，获取标题中内容
